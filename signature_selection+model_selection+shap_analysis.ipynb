{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zf1tkOYim8CH",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title Library import\n",
        "!pip install statkit\n",
        "!pip install shap\n",
        "!pip install imblearn\n",
        "from sklearn.dummy import DummyClassifier\n",
        "from sklearn.impute import SimpleImputer\n",
        "import os\n",
        "import sys\n",
        "import warnings\n",
        "from collections import Counter\n",
        "from sklearn.decomposition import PCA\n",
        "import shap\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import statsmodels.api as sm\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.ensemble import (AdaBoostClassifier, BaggingClassifier,\n",
        "                              GradientBoostingClassifier,\n",
        "                              RandomForestClassifier)\n",
        "from sklearn.feature_selection import (RFECV, SelectKBest, f_classif,\n",
        "                                       mutual_info_classif)\n",
        "from sklearn.linear_model import LassoCV, LogisticRegression, Perceptron\n",
        "from sklearn.metrics import (accuracy_score, auc, f1_score, precision_score,\n",
        "                             recall_score, roc_auc_score, roc_curve, balanced_accuracy_score)\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.utils import resample, shuffle\n",
        "from statkit.decision import NetBenefitDisplay\n",
        "from sklearn.metrics import precision_recall_curve, auc\n",
        "from sklearn.calibration import calibration_curve\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.feature_selection import SelectKBest, f_classif,chi2, mutual_info_classif\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "# import lightgbm as lgb\n",
        "\n",
        "# Required imports\n",
        "from sklearn.ensemble import (\n",
        "    RandomForestClassifier,\n",
        "    GradientBoostingClassifier,\n",
        "    AdaBoostClassifier,\n",
        "    BaggingClassifier,\n",
        "    ExtraTreesClassifier,\n",
        ")\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import (\n",
        "    LogisticRegression,\n",
        "    PassiveAggressiveClassifier,\n",
        "    RidgeClassifier,\n",
        ")\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.dummy import DummyClassifier\n",
        "from sklearn.model_selection import KFold, cross_val_score\n",
        "from sklearn.feature_selection import RFE\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kRQHGqyKtkDz",
        "outputId": "2753a4db-e5e5-4f50-aff7-a1a854b2947e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# @title Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yLWUtXJncwai",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title Classifiers\n",
        "from sklearn.ensemble import (\n",
        "    RandomForestClassifier,\n",
        "    GradientBoostingClassifier,\n",
        "    AdaBoostClassifier,\n",
        "    BaggingClassifier,\n",
        "    ExtraTreesClassifier,\n",
        ")\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "# K-Nearest Neighbors (KNN)\n",
        "knn_param_space = {\n",
        "    'n_neighbors': [3, 5],\n",
        "    'weights': ['uniform', 'distance'],\n",
        "    'algorithm': ['auto', 'ball_tree']\n",
        "}\n",
        "\n",
        "# AdaBoost Classifier (ABC)\n",
        "abc_param_space = {\n",
        "    'n_estimators': [50, 100],\n",
        "    'learning_rate': [0.01, 0.1],\n",
        "}\n",
        "\n",
        "# Logistic Regression (LRC)\n",
        "lr_param_space = {\n",
        "    'penalty': ['l2'],\n",
        "    'C': [0.1, 1],\n",
        "    'solver': ['lbfgs'],\n",
        "    'max_iter': [100]\n",
        "}\n",
        "\n",
        "# Random Forest Classifier (RFC)\n",
        "rf_param_space = {\n",
        "    'n_estimators': [50, 100],\n",
        "    'max_depth': [5, 10],\n",
        "    'max_features': ['sqrt']\n",
        "}\n",
        "\n",
        "# Decision Tree Classifier (DTC)\n",
        "dt_param_space = {\n",
        "    'max_depth': [5, 10],\n",
        "    'min_samples_split': [2, 5],\n",
        "    'max_features': ['sqrt']\n",
        "}\n",
        "\n",
        "# Support Vector Classifier (SVC)\n",
        "svc_param_space = {\n",
        "    'C': [0.1, 1],\n",
        "    'kernel': ['linear', 'rbf'],\n",
        "    'probability': [True]\n",
        "}\n",
        "\n",
        "# Gradient Boosting Classifier (GBC)\n",
        "gbc_param_space = {\n",
        "    'n_estimators': [50],\n",
        "    'learning_rate': [0.1],\n",
        "    'max_depth': [3, 5]\n",
        "}\n",
        "\n",
        "# Bagging Classifier (BAG)\n",
        "bg_param_space = {\n",
        "    'n_estimators': [50],\n",
        "    'max_samples': [0.5, 1.0]\n",
        "}\n",
        "\n",
        "# Multi-layer Perceptron (MLP)\n",
        "mlp_param_space = {\n",
        "    'hidden_layer_sizes': [(50,), (100,)],\n",
        "    'activation': ['relu'],\n",
        "    'solver': ['adam'],\n",
        "    'max_iter': [200]\n",
        "}\n",
        "\n",
        "# Gaussian Naive Bayes (GNB)\n",
        "gnb_param_space = {\n",
        "    'var_smoothing': [1e-9, 1e-7]\n",
        "}\n",
        "\n",
        "# Extra Trees Classifier (ETC)\n",
        "etc_param_space = {\n",
        "    'n_estimators': [50],\n",
        "    'max_depth': [5, 10],\n",
        "    'max_features': ['sqrt']\n",
        "}\n",
        "dum_param_space = {\n",
        "\n",
        "}\n",
        "\n",
        "\n",
        "# Classifiers Dictionary with Predict-Proba Support\n",
        "classifiers = {\n",
        "    'DUM': (DummyClassifier(strategy=\"uniform\"),dum_param_space),\n",
        "    'GNB': (GaussianNB(), gnb_param_space),\n",
        "    'MLP': (MLPClassifier(random_state=42), mlp_param_space),\n",
        "    'DTC': (DecisionTreeClassifier(random_state=42), dt_param_space),\n",
        "    'RFC': (RandomForestClassifier(random_state=42), rf_param_space),\n",
        "    'KNN': (KNeighborsClassifier(), knn_param_space),\n",
        "    'ABC': (AdaBoostClassifier(random_state=42), abc_param_space),\n",
        "    'LRC': (LogisticRegression(random_state=42), lr_param_space),\n",
        "    'SVC': (SVC(probability=True, random_state=42), svc_param_space),\n",
        "    'BAG': (BaggingClassifier(random_state=42), bg_param_space),\n",
        "    'GBC': (GradientBoostingClassifier(random_state=42), gbc_param_space),\n",
        "    'ETC': (ExtraTreesClassifier(random_state=42), etc_param_space),\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "JzGxo1RZgGKr"
      },
      "outputs": [],
      "source": [
        "# @title Parameters\n",
        "\n",
        "datasets = [\n",
        "            'transcriptomics'\n",
        "            'radiomics+pre_clinical',\n",
        "            'pre_clinical',\n",
        "            'radiomics',\n",
        "            'genomics',\n",
        "            'post_clinical',\n",
        "            'radiomics+post_clinical',\n",
        "            'genomics+post_clinical',\n",
        "            'radiomics+genomics+post_clinical',\n",
        "            'radiomics+genomics'\n",
        "            ]\n",
        "\n",
        "labels = pd.read_csv(\"/content/drive/MyDrive/Projects/Ongoing Projects/Radiogenomics/Featrures/titi_features/new/labels_titi.csv\")\n",
        "num_bootstraps = 100\n",
        "feature_selections = ['mi','anova','lasso']\n",
        "path = \"path_to_features\"\n",
        "backward_stepwise_selection_algorithms = [LogisticRegression(),Perceptron(),DecisionTreeClassifier(),GradientBoostingClassifier()]\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "def append_row(df, row):\n",
        "    return pd.concat([\n",
        "                df,\n",
        "                pd.DataFrame([row], columns=row.index)]\n",
        "          ).reset_index(drop=True)\n",
        "\n",
        "def backward_stepwise_selection(X, y, clf):\n",
        "\n",
        "  # Use RFECV with a RandomForest classifier\n",
        "  selector = RFE(estimator=clf,n_features_to_select=5)\n",
        "  selector.fit_transform(X, y)\n",
        "  features = selector.get_support(indices=True)\n",
        "\n",
        "  return features\n",
        "\n",
        "############### Selected Signatures ##################\n",
        "\n",
        "post_clinical_features = ['Gender', 'Ethnicity', 'Smoking status', '%GG', 'Tumor Location (choice=RUL)', 'Tumor Location (choice=RML)',\n",
        "                          'Tumor Location (choice=RLL)','Tumor Location (choice=LUL)', 'Tumor Location (choice=LLL)', 'Tumor Location (choice=L Lingula)']\n",
        "\n",
        "genomics_features = ['ACTG2', 'AGPS', 'ALG14', 'ANG', 'ANGPTL4', 'ANKRD29', 'ANXA1', 'APOC1', 'APOE']\n",
        "\n",
        "pre_clinical_features = ['Gender', 'Ethnicity', 'Smoking status', '%GG', 'Tumor Location (choice=RUL)', 'Tumor Location (choice=RML)',\n",
        "                         'Tumor Location (choice=RLL)','Tumor Location (choice=LUL)', 'Tumor Location (choice=LLL)', 'Tumor Location (choice=L Lingula)']\n",
        "\n",
        "radiomics_features = ['original_shape_Elongation', 'original_shape_Flatness', 'original_shape_LeastAxisLength', 'original_shape_MajorAxisLength',\n",
        "                      'original_shape_Maximum2DDiameterColumn', 'original_shape_Maximum2DDiameterRow', 'original_shape_Maximum2DDiameterSlice',\n",
        "                      'original_shape_Maximum3DDiameter', 'original_shape_MeshVolume', 'original_shape_MinorAxisLength']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "It0qsvK8dPp6"
      },
      "outputs": [],
      "source": [
        "# @title Feature Signature Selection (Corelation + Feature Selection + Backward Stepwise Selection + Classifier)\n",
        "\n",
        "main_y = pd.DataFrame(labels[\"Lymphovascular invasion\"]).iloc[:66,:]\n",
        "runs_df = pd.DataFrame()\n",
        "\n",
        "for dataset in datasets:\n",
        "\n",
        "  main_X = pd.read_csv(path+dataset+\".csv\",index_col=0,header=0).iloc[:66,:]\n",
        "\n",
        "  for feature_selection in feature_selections:\n",
        "    for backward_stepwise_selection_algorithm in backward_stepwise_selection_algorithms:\n",
        "\n",
        "      feature_counts = Counter()\n",
        "\n",
        "      # Shuffle data\n",
        "      data_shuffled, labels_shuffled = shuffle(main_X, main_y, random_state=42)\n",
        "      feature_names = data_shuffled.columns\n",
        "\n",
        "      # Standardize features\n",
        "      scaler = StandardScaler()\n",
        "      X_scaled = scaler.fit_transform(data_shuffled)\n",
        "\n",
        "      # SMOTE resampling\n",
        "      X_scaled, y = SMOTE(random_state=42).fit_resample(X_scaled,labels_shuffled)\n",
        "\n",
        "      ########### Corelation + Feature Selection\n",
        "      for i in range(num_bootstraps):\n",
        "\n",
        "          # Bootstrap sampling\n",
        "          X_resampled, y_resampled = resample(X_scaled, y, replace=True, random_state=i)\n",
        "\n",
        "          # Removing correlated features (|correlation| > 0.90)\n",
        "          corr_matrix = pd.DataFrame(X_resampled).corr().abs()\n",
        "          upper_triangle = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
        "          to_drop = [column for column in upper_triangle.columns if any(upper_triangle[column] > 0.90)]\n",
        "          X_resampled = pd.DataFrame(X_resampled).drop(columns=to_drop).values\n",
        "\n",
        "          # Feature selection\n",
        "          if feature_selection == 'anova':\n",
        "            feat_selec = SelectKBest(f_classif, k=10)\n",
        "            feat_selec.fit_transform(X_resampled, y_resampled)\n",
        "            selected_features = feat_selec.get_support(indices=True)\n",
        "            print(main_X.columns[selected_features])\n",
        "\n",
        "          elif feature_selection == 'mi':\n",
        "            feat_selec = SelectKBest(mutual_info_classif, k=10)\n",
        "            feat_selec.fit_transform(X_resampled, y_resampled)\n",
        "            selected_features = feat_selec.get_support(indices=True)\n",
        "            print(main_X.columns[selected_features])\n",
        "\n",
        "          elif feature_selection == 'lasso':\n",
        "            lasso = LassoCV(cv=5, random_state=0, max_iter=10000)\n",
        "            lasso.fit(X_resampled, y_resampled)\n",
        "            selected_features = np.where(lasso.coef_ != 0)[0]\n",
        "            print(main_X.columns[selected_features])\n",
        "\n",
        "          print('\\r'+str(round(i))+\"%\", end='', flush=True)\n",
        "\n",
        "          # Update feature count based on selected features\n",
        "          feature_counts.update(selected_features)\n",
        "\n",
        "      print('\\r', end='', flush=True)\n",
        "      most_common_features = [item for item, _ in feature_counts.most_common(10)]\n",
        "      print(\"\\nSelected features: \",most_common_features)\n",
        "      selected_features_list = []\n",
        "\n",
        "      ########### Backward Stepwise Selection\n",
        "      for i in range(num_bootstraps):\n",
        "\n",
        "          X_scaled = scaler.fit_transform(X)\n",
        "          y = main_y\n",
        "\n",
        "          # SMOTE resampling\n",
        "          X_scaled, y = SMOTE(random_state=42).fit_resample(X_scaled,y)\n",
        "\n",
        "          # Bootstrap sampling\n",
        "          X_resampled, y_resampled = resample(X_scaled[:,most_common_features], y, replace=True, random_state=i)\n",
        "\n",
        "          X_resampled = pd.DataFrame(X_resampled)\n",
        "          y_resampled = pd.DataFrame(y_resampled)\n",
        "\n",
        "          X_resampled = X_resampled.reset_index(drop=True)\n",
        "          y_resampled = y_resampled.reset_index(drop=True)\n",
        "\n",
        "          y = pd.Series(y_resampled[\"Lymphovascular invasion\"])\n",
        "\n",
        "          # Run backward stepwise selection\n",
        "          selected_features = backward_stepwise_selection(X_resampled, y, backward_stepwise_selection_algorithm)\n",
        "\n",
        "          print('\\r'+str(round(i))+\"%\", end='', flush=True)\n",
        "\n",
        "          selected_features_list.append(selected_features)\n",
        "\n",
        "      print('\\r', end='', flush=True)\n",
        "      # Convert each feature list to a tuple (since lists are not hashable, we use tuples)\n",
        "      feature_selections_tuples = [tuple(f) for f in selected_features_list]\n",
        "      # Count the frequency of each feature list\n",
        "      counter = Counter(feature_selections_tuples)\n",
        "      # Get the most common feature list and its count\n",
        "      most_common_feature_list = counter.most_common(1)\n",
        "      stfeatures = list(most_common_feature_list[0][0])\n",
        "      print(f\"Most selected feature signature: {list(feature_names[stfeatures])}\")\n",
        "      print(f\"Repeats: {most_common_feature_list[0][1]}\")\n",
        "\n",
        "\n",
        "      ########### Classifiers\n",
        "      for name, (clf, param_space) in classifiers.items():\n",
        "\n",
        "        for i in range(num_bootstraps):\n",
        "\n",
        "          print('\\r'+str(round(i))+\"%\", end='', flush=True)\n",
        "\n",
        "          X_train = main_X[list(feature_names[stfeatures])]\n",
        "          y_train = main_y\n",
        "          X_train, y_train = shuffle(X_train, y_train, random_state=42)\n",
        "\n",
        "          X_train_s, y_train_s = resample(X_train, y_train, replace=True, random_state=i)\n",
        "\n",
        "          scaler = StandardScaler()\n",
        "          X_train_n = pd.DataFrame(scaler.fit_transform(X_train_s))\n",
        "\n",
        "          cv_scores = {'ext_accuracy': [], 'accuracy': [],'val_accuracy': [], 'ext_roc_auc': [],'roc_auc': [], 'val_roc_auc': [],\n",
        "                       'ext_precision': [],'precision': [],'val_precision': [], 'ext_recall': [],'recall': [], 'val_recall': [],'ext_f1': [], 'val_f1': [], 'f1': []}\n",
        "\n",
        "          kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42,)\n",
        "          scores = cross_val_score(clf, X_train_n, y_train_s, cv=kf, scoring='roc_auc')\n",
        "          # Calculate metrics\n",
        "          cv_scores['roc_auc'].append(np.mean(scores))\n",
        "\n",
        "        # Average scores across all folds\n",
        "        print(str(bss_alg.__class__.__name__) +\",\"+ fs + \",\"+ dataset.split(\"/\")[-1] +\",\"+ name +\",\"+\n",
        "        str(np.mean(cv_scores['ext_accuracy']))+\",\"+str(np.mean(cv_scores['val_accuracy']))+\",\"+str(np.mean(cv_scores['accuracy']))+\",\"+str(np.mean(cv_scores['ext_roc_auc']))+\",\"+\n",
        "        str(np.mean(cv_scores['val_roc_auc']))+\",\"+str(np.mean(cv_scores['roc_auc']))+\",\"+str(np.mean(cv_scores['ext_precision']))+\",\"+str(np.mean(cv_scores['val_precision']))+\",\"+\n",
        "        str(np.mean(cv_scores['precision']))+\",\"+str(np.mean(cv_scores['ext_recall']))+\",\"+str(np.mean(cv_scores['val_recall']))+\",\"+str(np.mean(cv_scores['recall']))+\",\"+\",\"+\n",
        "        str(np.mean(cv_scores['ext_f1']))+\",\"+str(np.mean(cv_scores['val_f1']))+\",\"+str(np.mean(cv_scores['f1'])))\n",
        "\n",
        "        run_new_row = pd.Series({\"bss_alg\" : str(bss_alg.__class__.__name__)\n",
        "                                 ,\"sign\" : list(feature_names[stfeatures])\n",
        "                                 ,\"Repeats\": most_common_feature_list[0][1]\n",
        "                                 ,\"fs\": str(fs)\n",
        "                                 ,\"dataset\": dataset.split(\"/\")[-1]\n",
        "                                 ,\"classifier\": name\n",
        "                                 ,\"ext_accuracy\":str(np.mean(cv_scores['ext_accuracy']))\n",
        "                                 ,\"val_accuracy\":str(np.mean(cv_scores['val_accuracy']))\n",
        "                                 ,\"accuracy\":str(np.mean(cv_scores['accuracy']))\n",
        "                                 ,\"ext_roc_auc\":str(np.mean(cv_scores['ext_roc_auc']))\n",
        "                                 ,\"val_roc_auc\":str(np.mean(cv_scores['val_roc_auc']))\n",
        "                                 ,\"roc_auc\":str(np.mean(cv_scores['roc_auc']))\n",
        "                                 ,\"ext_precision\":str(np.mean(cv_scores['ext_precision']))\n",
        "                                 ,\"val_precision\":str(np.mean(cv_scores['val_precision']))\n",
        "                                 ,\"precision\":str(np.mean(cv_scores['precision']))\n",
        "                                 ,\"ext_recall\":str(np.mean(cv_scores['ext_recall']))\n",
        "                                 ,\"val_recall\":str(np.mean(cv_scores['val_recall']))\n",
        "                                 ,\"recall\":str(np.mean(cv_scores['recall']))\n",
        "                                 ,\"ext_f1\":str(np.mean(cv_scores['ext_f1']))\n",
        "                                 ,\"val_f1\":str(np.mean(cv_scores['val_f1']))\n",
        "                                 ,\"f1\":str(np.mean(cv_scores['f1']))})\n",
        "\n",
        "        runs_df = append_row(runs_df, run_new_row)\n",
        "\n",
        "        runs_df.to_csv(\"path_to_results.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1VDwLO0Lpo_y",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title First, validating the “best classifier” with the 48 VA hospital patients with NO bootstrapping or any resampling\n",
        "\n",
        "runs_df = pd.DataFrame()\n",
        "\n",
        "for dataset in datasets:\n",
        "  for name, (clf, param_space) in classifiers.items():\n",
        "\n",
        "    cv_scores = {'ext_accuracy': [], 'accuracy': [],'ext_roc_auc': [],'roc_auc': [],\n",
        "                  'ext_precision': [],'precision': [], 'ext_recall': [],'recall': [], 'ext_f1': [],  'f1': []}\n",
        "\n",
        "    X_train = pd.DataFrame()\n",
        "    X_test = pd.DataFrame()\n",
        "\n",
        "    y_train = pd.DataFrame(labels[\"Lymphovascular invasion\"]).iloc[:66,:]\n",
        "    y_test = pd.DataFrame(labels[\"Lymphovascular invasion\"]).iloc[66:,:]\n",
        "\n",
        "    for ds in dataset.split(\"+\"):\n",
        "      if ds == \"pre_clinical\":\n",
        "        features = pre_clinical_features\n",
        "      elif ds == \"radiomics\":\n",
        "        features = radiomics_features\n",
        "      elif ds == \"genomics\":\n",
        "        features = genomics_features\n",
        "      elif ds == \"post_clinical\":\n",
        "        features = post_clinical_features\n",
        "      else:\n",
        "        features = []\n",
        "      X_train = pd.concat([pd.read_csv(dataset+\".csv\",index_col=0,header=0)[features],X_train],axis=1).iloc[:66,:]\n",
        "      X_test = pd.concat([pd.read_csv(dataset+\".csv\",index_col=0,header=0)[features],X_test],axis=1).iloc[66:,:]\n",
        "\n",
        "    # Shuffling\n",
        "    X_train, y_train = shuffle(X_train, y_train, random_state=42)\n",
        "    X_test, y_test = shuffle(X_test, y_test, random_state=42)\n",
        "\n",
        "    # Normalization\n",
        "    scaler = StandardScaler()\n",
        "    X_train_n = pd.DataFrame(scaler.fit_transform(X_train))\n",
        "    X_test_n = pd.DataFrame(scaler.transform(X_test))\n",
        "\n",
        "    # fit\n",
        "    clf.fit(X_train_n, y_train)\n",
        "\n",
        "    # train predict\n",
        "    y_train_pred = clf.predict(X_train_n)\n",
        "    y_train_pred_proba = clf.predict_proba(X_train_n)[:, 1]\n",
        "\n",
        "    # test predict\n",
        "    y_pred_test = clf.predict(X_test_n)\n",
        "    y_pred_test_proba = clf.predict_proba(X_test_n)[:, 1]\n",
        "\n",
        "    cv_scores['accuracy'].append(accuracy_score(y_train, y_train_pred))\n",
        "    cv_scores['roc_auc'].append(roc_auc_score(y_train, y_train_pred_proba))\n",
        "    cv_scores['precision'].append(precision_score(y_train, y_train_pred))\n",
        "    cv_scores['recall'].append(recall_score(y_train, y_train_pred))\n",
        "    cv_scores['f1'].append(f1_score(y_train, y_train_pred))\n",
        "\n",
        "    cv_scores['ext_accuracy'].append(accuracy_score(y_test, y_pred_test))\n",
        "    cv_scores['ext_roc_auc'].append(roc_auc_score(y_test, y_pred_test_proba))\n",
        "    cv_scores['ext_precision'].append(precision_score(y_test, y_pred_test))\n",
        "    cv_scores['ext_recall'].append(recall_score(y_test, y_pred_test))\n",
        "    cv_scores['ext_f1'].append(f1_score(y_test, y_pred_test))\n",
        "\n",
        "    # Average scores across all folds\n",
        "    print(dataset.split(\"/\")[-1] +\",\"+ name +\",\"+\n",
        "    str(np.mean(cv_scores['ext_accuracy']))+\",\"+str(np.mean(cv_scores['accuracy']))+\",\"+str(np.mean(cv_scores['ext_roc_auc']))+\",\"+\n",
        "    str(np.mean(cv_scores['roc_auc']))+\",\"+str(np.mean(cv_scores['ext_precision']))+\",\"+\n",
        "    str(np.mean(cv_scores['precision']))+\",\"+str(np.mean(cv_scores['ext_recall']))+\",\"+str(np.mean(cv_scores['recall']))+\",\"+\n",
        "    str(np.mean(cv_scores['ext_f1']))+\",\"+str(np.mean(cv_scores['f1'])))\n",
        "\n",
        "\n",
        "    run_new_row = pd.Series({\"dataset\": dataset.split(\"/\")[-1]\n",
        "                            ,\"classifier\": name\n",
        "                            ,\"ext_accuracy\":str(np.mean(cv_scores['ext_accuracy']))\n",
        "                            ,\"accuracy\":str(np.mean(cv_scores['accuracy']))\n",
        "                            ,\"ext_roc_auc\":str(np.mean(cv_scores['ext_roc_auc']))\n",
        "                            ,\"roc_auc\":str(np.mean(cv_scores['roc_auc']))\n",
        "                            ,\"ext_precision\":str(np.mean(cv_scores['ext_precision']))\n",
        "                            ,\"precision\":str(np.mean(cv_scores['precision']))\n",
        "                            ,\"ext_recall\":str(np.mean(cv_scores['ext_recall']))\n",
        "                            ,\"recall\":str(np.mean(cv_scores['recall']))\n",
        "                            ,\"ext_f1\":str(np.mean(cv_scores['ext_f1']))\n",
        "                            ,\"f1\":str(np.mean(cv_scores['f1']))})\n",
        "\n",
        "    runs_df = append_row(runs_df, run_new_row)\n",
        "\n",
        "  runs_df.to_csv(\"model_results.csv\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7oU2TAMew3o_",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title Second, I would take a bootstrap size of 48 patients, but without stratifying for LVI+ or LVI-.\n",
        "\n",
        "res_df = pd.DataFrame()\n",
        "runs_df = pd.DataFrame()\n",
        "raws = [False]\n",
        "featuss = []\n",
        "for dataset in datasets:\n",
        "  for name, (clf, param_space) in classifiers2.items():\n",
        "    for raw in raws:\n",
        "\n",
        "      cv_scores = {'ext_accuracy': [], 'accuracy': [],'ext_roc_auc': [],'roc_auc': [],\n",
        "                    'ext_precision': [],'precision': [], 'ext_recall': [],'recall': [], 'ext_f1': [],  'f1': [],  'features': []}\n",
        "\n",
        "      X_train = pd.DataFrame()\n",
        "      X_test = pd.DataFrame()\n",
        "\n",
        "      y_train = pd.DataFrame(labels[\"Lymphovascular invasion\"]).iloc[:66,:]\n",
        "      y_test = pd.DataFrame(labels[\"Lymphovascular invasion\"]).iloc[66:,:]\n",
        "\n",
        "      for ds in dataset.split(\"+\"):\n",
        "        if ds == \"pre_clinical\":\n",
        "          features = pre_clinical_features\n",
        "        elif ds == \"radiomics\":\n",
        "          features = radiomics_features\n",
        "        elif ds == \"genomics\":\n",
        "          features = genomics_features\n",
        "        elif ds == \"post_clinical\":\n",
        "          features = post_clinical_features\n",
        "        else:\n",
        "          features = []\n",
        "        if raw:\n",
        "          X_train = pd.concat([pd.read_csv(path+dataset+\".csv\",index_col=0,header=0),X_train],axis=1).iloc[:66,:]\n",
        "          X_test = pd.concat([pd.read_csv(path+dataset+\".csv\",index_col=0,header=0),X_test],axis=1).iloc[66:,:]\n",
        "        else:\n",
        "          X_train = pd.concat([pd.read_csv(path+dataset+\".csv\",index_col=0,header=0)[features],X_train],axis=1).iloc[:66,:]\n",
        "          X_test = pd.concat([pd.read_csv(path+dataset+\".csv\",index_col=0,header=0)[features],X_test],axis=1).iloc[66:,:]\n",
        "\n",
        "      df_X_train = X_train\n",
        "      df_X_test = X_test\n",
        "\n",
        "      # Shuffling\n",
        "      X_train, y_train = shuffle(df_X_train, y_train, random_state=42)\n",
        "      X_test, y_test = shuffle(df_X_test, y_test, random_state=42)\n",
        "\n",
        "      X_train, y_train = SMOTE(random_state=42).fit_resample(X_train,y_train)\n",
        "\n",
        "      # Normalization\n",
        "      scaler = StandardScaler()\n",
        "      X_train_n = pd.DataFrame(scaler.fit_transform(X_train))\n",
        "      X_test_n = pd.DataFrame(scaler.transform(X_test))\n",
        "\n",
        "      # fit\n",
        "      grid_search = GridSearchCV(estimator=clf, param_grid=param_space, cv=5, scoring='accuracy')\n",
        "      grid_search.fit(X_train_n, y_train)\n",
        "      best_regressor = grid_search.best_estimator_\n",
        "\n",
        "      shap.initjs()\n",
        "\n",
        "      explainer = shap.Explainer(best_regressor.predict,X_train_n)\n",
        "\n",
        "\n",
        "      cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "      accuracy_scores = cross_val_score(best_regressor, X_train_n, y_train, cv=cv, scoring='accuracy')\n",
        "      roc_auc_scores = cross_val_score(best_regressor, X_train_n, y_train, cv=cv, scoring='roc_auc')\n",
        "      f1_scores = cross_val_score(best_regressor, X_train_n, y_train, cv=cv, scoring='f1')\n",
        "      precision_scores = cross_val_score(best_regressor, X_train_n, y_train, cv=cv, scoring='precision')\n",
        "      recall_scores = cross_val_score(best_regressor, X_train_n, y_train, cv=cv, scoring='recall')\n",
        "\n",
        "      # train predict\n",
        "      # y_train_pred = best_regressor.predict(X_train_n)\n",
        "      # y_train_pred_proba = best_regressor.predict_proba(X_train_n)[:, 1]\n",
        "\n",
        "      cv_scores['accuracy'].append(accuracy_scores)\n",
        "      cv_scores['roc_auc'].append(roc_auc_scores)\n",
        "      cv_scores['precision'].append(precision_scores)\n",
        "      cv_scores['recall'].append(recall_scores)\n",
        "      cv_scores['f1'].append(f1_scores)\n",
        "      cv_scores['features'].append(features)\n",
        "\n",
        "      for i in range(100):\n",
        "\n",
        "        print('\\r'+str(round(i))+\"%\", end='', flush=True)\n",
        "\n",
        "        X_test_s, y_test_s = resample(X_test_n, y_test, replace=True, random_state=100+i)\n",
        "\n",
        "        # test predict\n",
        "        y_pred_test = best_regressor.predict(X_test_s)\n",
        "        y_pred_test_proba = best_regressor.predict_proba(X_test_s)[:, 1]\n",
        "\n",
        "        shap_values = explainer(X_test_s)\n",
        "        # print(shap_values.values)\n",
        "        shap_importance = np.abs(shap_values.values).mean(axis=0)\n",
        "        shap_importance_df = pd.DataFrame({'Feature': df_X_train.columns, 'Importance': shap_importance})\n",
        "        top_10_features = shap_importance_df.sort_values(by='Importance', ascending=False).head(10)\n",
        "        features = top_10_features['Feature'].to_list()\n",
        "        res_df = pd.concat([res_df,pd.DataFrame(top_10_features)])\n",
        "        featuss.extend(features)\n",
        "\n",
        "        res_df.to_csv(\"feats_rf.csv\")\n",
        "\n",
        "        print(list(y_test_s[\"Lymphovascular invasion\"]))\n",
        "        print(list(y_pred_test))\n",
        "        print(list(y_pred_test_proba))\n",
        "\n",
        "        cv_scores['ext_accuracy'].append(accuracy_score(y_test_s, y_pred_test))\n",
        "        cv_scores['ext_roc_auc'].append(roc_auc_score(y_test_s, y_pred_test_proba))\n",
        "        cv_scores['ext_precision'].append(precision_score(y_test_s, y_pred_test))\n",
        "        cv_scores['ext_recall'].append(recall_score(y_test_s, y_pred_test))\n",
        "        cv_scores['ext_f1'].append(f1_score(y_test_s, y_pred_test))\n",
        "\n",
        "      # Average scores across all folds\n",
        "      print(dataset.split(\"/\")[-1] +\",\"+ name +\",\"+ str(raw)+\",\"+\n",
        "      str(np.mean(cv_scores['ext_accuracy']))+\",\"+str(np.mean(cv_scores['accuracy']))+\",\"+str(np.mean(cv_scores['ext_roc_auc']))+\",\"+\n",
        "      str(np.mean(cv_scores['roc_auc']))+\",\"+str(np.mean(cv_scores['ext_precision']))+\",\"+\n",
        "      str(np.mean(cv_scores['precision']))+\",\"+str(np.mean(cv_scores['ext_recall']))+\",\"+str(np.mean(cv_scores['recall']))+\",\"+\n",
        "      str(np.mean(cv_scores['ext_f1']))+\",\"+str(np.mean(cv_scores['f1'])))\n",
        "\n",
        "      run_new_row = pd.Series({\"dataset\": dataset.split(\"/\")[-1]\n",
        "                              ,\"classifier\": name\n",
        "                              ,\"raw\": str(raw)\n",
        "                              ,\"ext_accuracy\":str(np.mean(cv_scores['ext_accuracy']))\n",
        "                              ,\"ext_accuracy_std\":str(np.std(cv_scores['ext_accuracy']))\n",
        "                              ,\"accuracy\":str(np.mean(cv_scores['accuracy']))\n",
        "                              ,\"ext_roc_auc\":str(np.mean(cv_scores['ext_roc_auc']))\n",
        "                              ,\"ext_roc_auc_std\":str(np.std(cv_scores['ext_roc_auc']))\n",
        "                              ,\"roc_auc\":str(np.mean(cv_scores['roc_auc']))\n",
        "                              ,\"ext_precision\":str(np.mean(cv_scores['ext_precision']))\n",
        "                              ,\"ext_precision_std\":str(np.std(cv_scores['ext_precision']))\n",
        "                              ,\"precision\":str(np.mean(cv_scores['precision']))\n",
        "                              ,\"ext_recall\":str(np.mean(cv_scores['ext_recall']))\n",
        "                              ,\"ext_recall_std\":str(np.std(cv_scores['ext_recall']))\n",
        "                              ,\"recall\":str(np.mean(cv_scores['recall']))\n",
        "                              ,\"ext_f1\":str(np.mean(cv_scores['ext_f1']))\n",
        "                              ,\"ext_f1_std\":str(np.std(cv_scores['ext_f1']))\n",
        "                              ,\"f1\":str(np.mean(cv_scores['f1']))\n",
        "                              ,\"features\":str(features)})\n",
        "\n",
        "      runs_df = append_row(runs_df, run_new_row)\n",
        "\n",
        "    runs_df.to_csv(\"/content/drive/MyDrive/Projects/Ongoing Projects/Radiogenomics/model_results_20.csv\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1_oRchb3427_",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title Running Classifiers\n",
        "if not sys.warnoptions:\n",
        "    warnings.simplefilter(\"ignore\")\n",
        "    os.environ[\"PYTHONWARNINGS\"] = \"ignore\" # Also affect subprocesses\n",
        "path = \"/content/drive/MyDrive/Projects/Ongoing Projects/Radiogenomics/Featrures/titi_features/new/\"\n",
        "\n",
        "runs_df = pd.DataFrame()\n",
        "\n",
        "# selected signatures\n",
        "datasets = [\n",
        "            'pre_clinical',\n",
        "            'radiomics',\n",
        "            'genomics',\n",
        "            'post_clinical',\n",
        "            'radiomics+pre_clinical',\n",
        "            # 'radiomics+post_clinical',\n",
        "            'genomics+post_clinical',\n",
        "            # 'radiomics+genomics+post_clinical',\n",
        "            # 'radiomics+genomics'\n",
        "            ]\n",
        "\n",
        "\n",
        "post_clinical_features = ['Gender', 'Ethnicity', 'Smoking status', '%GG', 'Tumor Location (choice=RUL)', 'Tumor Location (choice=RML)',\n",
        "                          'Tumor Location (choice=RLL)','Tumor Location (choice=LUL)', 'Tumor Location (choice=LLL)', 'Tumor Location (choice=L Lingula)']\n",
        "\n",
        "genomics_features = ['ACTG2', 'AGPS', 'ALG14', 'ANG', 'ANGPTL4', 'ANKRD29', 'ANXA1', 'APOC1', 'APOE']\n",
        "\n",
        "pre_clinical_features = ['Gender', 'Ethnicity', 'Smoking status', '%GG', 'Tumor Location (choice=RUL)', 'Tumor Location (choice=RML)',\n",
        "                         'Tumor Location (choice=RLL)','Tumor Location (choice=LUL)', 'Tumor Location (choice=LLL)', 'Tumor Location (choice=L Lingula)']\n",
        "\n",
        "radiomics_features = ['original_shape_Elongation', 'original_shape_Flatness', 'original_shape_LeastAxisLength', 'original_shape_MajorAxisLength',\n",
        "                      'original_shape_Maximum2DDiameterColumn', 'original_shape_Maximum2DDiameterRow', 'original_shape_Maximum2DDiameterSlice',\n",
        "                      'original_shape_Maximum3DDiameter', 'original_shape_MeshVolume', 'original_shape_MinorAxisLength']\n",
        "\n",
        "# fig, ax = plt.subplots(figsize=(10, 6))\n",
        "# trajectories = {\n",
        "#                  'radiomics+pre_clinical' : ('radiomics+pre_clinical', False, classifiers2[\"GBC\"]),\n",
        "#                  'pre_clinical' : ('pre_clinical', False, classifiers2[\"GNB\"]),\n",
        "#                  'radiomics' : ('radiomics', False, classifiers2[\"DTC\"]),\n",
        "#                  'genomics' : ('genomics', False, classifiers2[\"SVC\"]),\n",
        "#                  'post_clinical' : ('post_clinical', False, classifiers2[\"GNB\"]),\n",
        "#                  'radiomics+post_clinical' : ('radiomics+post_clinical', False, classifiers2[\"GBC\"]),\n",
        "#                  'genomics+post_clinical' : ('genomics+post_clinical', False, classifiers2[\"GNB\"]),\n",
        "#                  'radiomics+genomics+post_clinical' : ('radiomics+genomics+post_clinical', False, classifiers2[\"ABC\"]),\n",
        "#                  'radiomics+genomics' : ('radiomics+genomics', False,  classifiers2[\"SVC\"])\n",
        "#                  }\n",
        "\n",
        "# trajectories = {\n",
        "#                  'genomics' : ('genomics', True, classifiers2[\"GNB\"]),\n",
        "#                  'post_clinical' : ('post_clinical', True, classifiers2[\"GNB\"]),\n",
        "#                 #  'radiomics+post_clinical' : ('radiomics+post_clinical', True, classifiers2[\"LRC\"]),\n",
        "#                  'genomics+post_clinical' : ('genomics+post_clinical', True, classifiers2[\"GNB\"]),\n",
        "#                 #  'radiomics+genomics+post_clinical' : ('radiomics+genomics+post_clinical', True, classifiers2[\"GNB\"]),\n",
        "#                 #  'radiomics+genomics' : ('radiomics+genomics', True,  classifiers2[\"GNB\"]),\n",
        "#                 #  'radiomics' : ('radiomics', False, classifiers2[\"DTC\"]),\n",
        "#                  }\n",
        "\n",
        "# n_stage = pd.read_csv(\"post_clinical.csv\",index_col=0,header=0).iloc[66:,13].replace(2, 1)\n",
        "\n",
        "# trajectories = {\n",
        "#                   # 'radiomics+pre_clinical' : ('radiomics+pre_clinical', True, classifiers2[\"KNN\"]),\n",
        "#                 #  'pre_clinical' : ('pre_clinical', True, classifiers2[\"GNB\"]),\n",
        "#                 #  'radiomics' : ('radiomics', False, classifiers2[\"DTC\"]),\n",
        "#                 #  'genomics' : ('genomics', True, classifiers2[\"GNB\"])\n",
        "#                 #  'post_clinical' : ('post_clinical', True, classifiers2[\"GNB\"]),\n",
        "#                 #  'radiomics+post_clinical' : ('radiomics+post_clinical', True, classifiers2[\"LRC\"]),\n",
        "#                 #  'genomics+post_clinical' : ('genomics+post_clinical', True, classifiers2[\"GNB\"]),\n",
        "#                 #  'radiomics+genomics+post_clinical' : ('radiomics+genomics+post_clinical', True, classifiers2[\"GNB\"]),\n",
        "#                 #  'radiomics+genomics' : ('radiomics+genomics', True,  classifiers2[\"GNB\"])\n",
        "#                  }\n",
        "\n",
        "trajectories = {\n",
        "                 'radiomics+pre_clinical' : ('radiomics+pre_clinical', True, classifiers2[\"KNN\"]),\n",
        "                #  'pre_clinical' : ('pre_clinical', True, classifiers2[\"GNB\"]),\n",
        "                #  'radiomics' : ('radiomics', True, classifiers2[\"LRC\"]),\n",
        "                #  'radiomics+pre_clinical' : ('radiomics+pre_clinical', False, classifiers2[\"GBC\"]),\n",
        "                 'pre_clinical' : ('pre_clinical', False, classifiers2[\"GNB\"]),\n",
        "                 'radiomics' : ('radiomics', False, classifiers2[\"DTC\"]),\n",
        "                 }\n",
        "\n",
        "\n",
        "# fig, ax = plt.subplots(figsize=(8, 6))\n",
        "\n",
        "for trajectory in trajectories.values():\n",
        "\n",
        "  clf = trajectory[2][0]\n",
        "  param_space = trajectory[2][1]\n",
        "  raw = trajectory[1]\n",
        "  name = trajectory[2][0].__class__.__name__\n",
        "  dataset = trajectory[0]\n",
        "\n",
        "  cv_scores = {'ext_accuracy': [], 'accuracy': [],'ext_roc_auc': [],'roc_auc': [],\n",
        "                'ext_precision': [],'precision': [], 'ext_recall': [],'recall': [], 'ext_f1': [],  'f1': [],  'features': []}\n",
        "\n",
        "  X_train = pd.DataFrame()\n",
        "  X_test = pd.DataFrame()\n",
        "\n",
        "  y_train = pd.DataFrame(labels[\"Lymphovascular invasion\"]).iloc[:66,:]\n",
        "  y_test = pd.DataFrame(labels[\"Lymphovascular invasion\"]).iloc[66:,:]\n",
        "\n",
        "  for ds in dataset.split(\"+\"):\n",
        "    if ds == \"pre_clinical\":\n",
        "      features = pre_clinical_features\n",
        "    elif ds == \"radiomics\":\n",
        "      features = radiomics_features\n",
        "    elif ds == \"genomics\":\n",
        "      features = genomics_features\n",
        "    elif ds == \"post_clinical\":\n",
        "      features = post_clinical_features\n",
        "    else:\n",
        "      features = []\n",
        "    if raw:\n",
        "      X_train = pd.concat([pd.read_csv(path+dataset+\".csv\",index_col=0,header=0),X_train],axis=1).iloc[:66,:]\n",
        "      X_test = pd.concat([pd.read_csv(path+dataset+\".csv\",index_col=0,header=0),X_test],axis=1).iloc[66:,:]\n",
        "    else:\n",
        "      X_train = pd.concat([pd.read_csv(path+dataset+\".csv\",index_col=0,header=0)[features],X_train],axis=1).iloc[:66,:]\n",
        "      X_test = pd.concat([pd.read_csv(path+dataset+\".csv\",index_col=0,header=0)[features],X_test],axis=1).iloc[66:,:]\n",
        "\n",
        "  df_X_train = X_train\n",
        "  df_X_test = X_test\n",
        "\n",
        "  # Shuffling\n",
        "  X_train, y_train = shuffle(df_X_train, y_train, random_state=42)\n",
        "  X_test, y_test = shuffle(df_X_test, y_test, random_state=42)\n",
        "\n",
        "  X_train, y_train = SMOTE(random_state=42).fit_resample(X_train,y_train)\n",
        "\n",
        "  # Normalization\n",
        "  scaler = StandardScaler()\n",
        "  X_train_n = pd.DataFrame(scaler.fit_transform(X_train))\n",
        "  X_test_n = pd.DataFrame(scaler.transform(X_test))\n",
        "\n",
        "  # fit\n",
        "  grid_search = GridSearchCV(estimator=clf, param_grid=param_space, cv=5, scoring='roc_auc')\n",
        "  grid_search.fit(X_train_n, y_train)\n",
        "  best_regressor = grid_search.best_estimator_\n",
        "\n",
        "  # '''\n",
        "  # shap.initjs()\n",
        "\n",
        "  # explainer = shap.Explainer(best_regressor.predict,X_train_n)\n",
        "  # shap_values = explainer(X_train_n,max_evals=1000)\n",
        "  # shap_importance = np.abs(shap_values.values).mean(axis=0)\n",
        "  # shap_importance_df = pd.DataFrame({'Feature': df_X_train.columns, 'Importance': shap_importance})\n",
        "  # top_10_features = shap_importance_df.sort_values(by='Importance', ascending=False).head(10)\n",
        "  # features = top_10_features['Feature'].to_list()\n",
        "\n",
        "  # new = []\n",
        "  # for x in features:\n",
        "  #   x = x.replace(\"original_shape_\",\"\")\n",
        "  #   # wrapper = textwrap.TextWrapper(width=10)\n",
        "  #   # word_list = wrapper.wrap(text=x)\n",
        "  #   # n_w_l = ''\n",
        "  #   # for word in word_list[:2]:\n",
        "  #   #   n_w_l = n_w_l + \"\\n\"+word\n",
        "  #   new.append(x)\n",
        "\n",
        "  # # plt.figure(figsize=(8, 6))\n",
        "\n",
        "  # # Plot the bar plot\n",
        "  # plt.figure(figsize=(20, 10))  # Adjust figure size as needed\n",
        "  # plt.bar(new, top_10_features['Importance'],color='blue')\n",
        "  # plt.xlabel('SHAP Importance')\n",
        "  # plt.ylabel('Feature')\n",
        "  # plt.title('Top 10 Important Features (SHAP)')\n",
        "  # # lt.gca().invert_yaxis()  # Invert y-axis for top-to-bottom order\n",
        "  # plt.show()\n",
        "  # '''\n",
        "\n",
        "  # train predict\n",
        "  y_train_pred = best_regressor.predict(X_train_n)\n",
        "  y_train_pred_proba = best_regressor.predict_proba(X_train_n)[:, 1]\n",
        "\n",
        "  cv_scores['accuracy'].append(accuracy_score(y_train, y_train_pred))\n",
        "  cv_scores['roc_auc'].append(roc_auc_score(y_train, y_train_pred_proba))\n",
        "  cv_scores['precision'].append(precision_score(y_train, y_train_pred))\n",
        "  cv_scores['recall'].append(recall_score(y_train, y_train_pred))\n",
        "  cv_scores['f1'].append(f1_score(y_train, y_train_pred))\n",
        "  cv_scores['features'].append(features)\n",
        "\n",
        "  all_y = []\n",
        "  all_preds = []\n",
        "  all_preds_proba = []\n",
        "\n",
        "  for i in range(100):\n",
        "\n",
        "    print('\\r'+str(round(i))+\"%\", end='', flush=True)\n",
        "\n",
        "    X_test_s, y_test_s = resample(X_test_n, y_test, replace=False, random_state=100+i,stratify=y_test)\n",
        "\n",
        "    # test predict\n",
        "    y_pred_test = best_regressor.predict(X_test_s)\n",
        "    y_pred_test_proba = best_regressor.predict_proba(X_test_s)[:, 1]\n",
        "\n",
        "    # print(list(y_test_s[\"Lymphovascular invasion\"]))\n",
        "    # print(list(y_pred_test))\n",
        "    # print(list(y_pred_test_proba))\n",
        "\n",
        "\n",
        "\n",
        "    all_y.extend(list(y_test_s['Lymphovascular invasion']))\n",
        "    all_preds.extend(list(y_pred_test))\n",
        "    all_preds_proba.extend(list(y_pred_test_proba))\n",
        "\n",
        "  print(all_y)\n",
        "  print(all_preds)\n",
        "  print(all_preds_proba)\n",
        "\n",
        "  cv_scores['ext_accuracy'].append(accuracy_score(all_y, all_preds))\n",
        "  cv_scores['ext_roc_auc'].append(roc_auc_score(all_y, all_preds_proba))\n",
        "  cv_scores['ext_precision'].append(precision_score(all_y, all_preds))\n",
        "  cv_scores['ext_recall'].append(recall_score(all_y, all_preds))\n",
        "  cv_scores['ext_f1'].append(f1_score(all_y, all_preds))\n",
        "\n",
        "  # Average scores across all folds\n",
        "  print(dataset.split(\"/\")[-1] +\",\"+ name +\",\"+ str(raw)+\",\"+\n",
        "  str(np.mean(cv_scores['ext_accuracy']))+\",\"+str(np.mean(cv_scores['accuracy']))+\",\"+str(np.mean(cv_scores['ext_roc_auc']))+\",\"+\n",
        "  str(np.mean(cv_scores['roc_auc']))+\",\"+str(np.mean(cv_scores['ext_precision']))+\",\"+\n",
        "  str(np.mean(cv_scores['precision']))+\",\"+str(np.mean(cv_scores['ext_recall']))+\",\"+str(np.mean(cv_scores['recall']))+\",\"+\n",
        "  str(np.mean(cv_scores['ext_f1']))+\",\"+str(np.mean(cv_scores['f1'])))\n",
        "\n",
        "  fpr, tpr, thresholds = roc_curve(all_y, all_preds_proba)\n",
        "  roc_auc = auc(fpr, tpr)\n",
        "  name = name.replace(\"KNeighborsClassifier\", \"KNN\").replace(\"DecisionTreeClassifier\",\"DTC\").replace(\"GaussianNB\",\"GNB\")\n",
        "\n",
        "  plt.plot(fpr, tpr, label=name+\" / \"+dataset.replace(\"genomics\",\"TF\").replace(\"radiomics\",\"RF\").replace(\"post_clinical\",\"PostOp_CF\").replace(\"pre_clinical\",\"PreOp_CF\")+\"\\n\"+f\"(AUC = {roc_auc:.2f}) \",linestyle='-.', lw=2 )\n",
        "  plt.fill_between(fpr, tpr, alpha=0.1)\n",
        "\n",
        "  # y_scores_jittered = y_pred_test_proba + np.random.normal(0, 0.2, len(y_pred_test_proba))\n",
        "\n",
        "  # display = NetBenefitDisplay.from_predictions(np.array(list(y_test_s[\"Lymphovascular invasion\"])), y_pred_test_proba, name=dataset,thresholds=np.linspace(0, 1, 100))\n",
        "  # ax.grid(True)\n",
        "  # if dataset=='radiomics+genomics':\n",
        "  #   display.plot(True,ax=ax)\n",
        "  # else:\n",
        "  #   display.plot(False,ax=ax)\n",
        "\n",
        "  run_new_row = pd.Series({\"dataset\": dataset.split(\"/\")[-1]\n",
        "                          ,\"classifier\": name\n",
        "                          ,\"raw\": str(raw)\n",
        "                          ,\"ext_accuracy\":str(np.mean(cv_scores['ext_accuracy']))\n",
        "                          ,\"accuracy\":str(np.mean(cv_scores['accuracy']))\n",
        "                          ,\"ext_roc_auc\":str(np.mean(cv_scores['ext_roc_auc']))\n",
        "                          ,\"roc_auc\":str(np.mean(cv_scores['roc_auc']))\n",
        "                          ,\"ext_precision\":str(np.mean(cv_scores['ext_precision']))\n",
        "                          ,\"precision\":str(np.mean(cv_scores['precision']))\n",
        "                          ,\"ext_recall\":str(np.mean(cv_scores['ext_recall']))\n",
        "                          ,\"recall\":str(np.mean(cv_scores['recall']))\n",
        "                          ,\"ext_f1\":str(np.mean(cv_scores['ext_f1']))\n",
        "                          ,\"f1\":str(np.mean(cv_scores['f1']))\n",
        "                          ,\"features\":str(features)})\n",
        "\n",
        "  runs_df = append_row(runs_df, run_new_row)\n",
        "\n",
        "# runs_df.to_csv(\"model_results_15.csv\")\n",
        "# Plot the ROC curve\n",
        "plt.plot([0, 1], [0, 1], color='grey', linestyle='--', lw=1)  # Diagonal line\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('(ROC) Curve --> PreOperative Prediction')\n",
        "plt.legend(loc='lower right')\n",
        "plt.grid()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title XAI - SHAP analysis\n",
        "\n",
        "df = pd.read_csv('gen_all.csv').iloc[:9,:]\n",
        "# df = pd.read_csv('gen_sel.csv').iloc[:9,:]\n",
        "\n",
        "# Create the plot with custom figure size\n",
        "plt.figure(figsize=(6, 10))\n",
        "\n",
        "# Horizontal bar plot\n",
        "plt.barh(df['gene'][::-1], df['mean'][::-1]/0.036, xerr=df['std'][::-1]/0.036, capsize=5, color=(251/255, 0/255, 61/255), edgecolor='black',zorder=3)\n",
        "# plt.barh(df['gene'][::-1], df['mean'][::-1]/0.162, xerr=df['std'][::-1]/0.162, capsize=5, color=(15/255, 115/255, 248/255), edgecolor='black')\n",
        "\n",
        "# Add labels and title\n",
        "plt.xlabel('Mean',fontsize=20)\n",
        "plt.ylabel('TF',fontsize=20)\n",
        "# plt.title('Horizontal Bar Plot with Grid')\n",
        "\n",
        "# Add grid behind bars\n",
        "plt.grid(axis='x', linestyle='--', alpha=0.7, zorder=0)\n",
        "plt.gca().patch.set_facecolor('white')  # Optional: ensures grid visibility with light bar colors\n",
        "plt.xlim(0,1.3)\n",
        "\n",
        "plt.xticks(fontsize=12)\n",
        "plt.yticks(fontsize=20)\n",
        "\n",
        "# Adjust bar z-order to be above the grid\n",
        "for bar in plt.gca().patches:\n",
        "    bar.set_zorder(2)\n",
        "\n",
        "# Show the plot\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "BqGb81MkIoGq",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.8rc1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}